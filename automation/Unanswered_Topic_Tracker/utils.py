from typing import List, Dict, Any
from bs4 import BeautifulSoup
import json

def parse_graph_chat_messages(messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    Parse chat messages from Microsoft Graph API /chats/messages endpoint,
    extract clean text content and reply-to relationships.

    Args:
        messages (List[Dict]): List of message dicts from Graph API.

    Returns:
        List[Dict]: Each message with id, sender, text, timestamp, and reply_to_id (if available)
    """
    parsed = []

    for msg in messages:
        msg_id = msg.get('id', '')
        if msg.get('from') is None:
            continue
        
        sender = msg.get('from', {}).get('user', {}).get('displayName', 'Unknown')
        html_content = msg.get('body', {}).get('content', '')
        timestamp = msg.get('createdDateTime', '')
        reply_to_id = []

        # è™•ç† reply-to è¨Šæ¯é—œä¿‚
        attachments = msg.get('attachments', [])
        for attachment in attachments:
            if attachment.get("contentType") == "messageReference":
                try:
                    # `attachment['content']` æ˜¯ä¸€å€‹ JSON å­—ä¸²
                    referenced_msg = json.loads(attachment.get("content", "{}"))
                    if reply_to_id is not None:
                        reply_to_id.append({"msg_id":referenced_msg.get("messageId")
                                            , "sender":referenced_msg.get("messageSender").get('user').get('displayName')
                                            , "msg_preview":referenced_msg.get("messagePreview")})  # <-- é€™æ˜¯åŸå§‹è¨Šæ¯ ID
                    # å¯æ“´å……ï¼šä¹Ÿå¯ä»¥æŠ“ preview æˆ– sender åå­—
                except Exception as e:
                    print(f"Error parsing messageReference: {e}")

        # ä½¿ç”¨ BeautifulSoup æ¸…é™¤ HTML
        soup = BeautifulSoup(html_content, 'html.parser')
        clean_text = soup.get_text(separator='\n').strip()

        parsed.append({
            "id": msg_id,
            "sender": sender,
            "text": clean_text,
            "timestamp": timestamp,
            "reply_to_id": None if len(reply_to_id)==0 else reply_to_id
        })

    return parsed

def make_prompt_for_unanswered_questions(processed_msgs: List[Dict], max_len=None):
    """
    å°‡è™•ç†å¥½çš„è¨Šæ¯åˆ—è¡¨è£½ä½œæˆçµ¦ LLM çš„ promptã€‚
    åŒ…å«å›è¦†è¨Šæ¯çš„ sender èˆ‡ msg_previewï¼Œè®“ LLM æ›´å®¹æ˜“åˆ¤æ–·æ˜¯å¦æœ‰å›æ‡‰ã€‚

    Args:
        processed_msgs (List[Dict]): 
            æ¯å‰‡è¨Šæ¯ dict åŒ…å« keys: "id", "sender", "text", "timestamp",
            é¸ç”¨ key: "reply_to_id" -> list of dicts: [{"msg_id", "sender", "msg_preview"}]

    Returns:
        str: ç”¨æ–¼èªæ„åˆ†æçš„ prompt å­—ä¸²
    """
    # æ™‚é–“æ’åº
    sorted_msgs = sorted(processed_msgs, key=lambda x: x.get('timestamp', ''))

    dialog_lines = []
    for count, msg in enumerate(sorted_msgs):
        if max_len:
            if count >= max_len:
                break

        time = msg.get('timestamp', 'æœªçŸ¥æ™‚é–“')
        sender = msg.get('sender', 'æœªçŸ¥ç™¼è©±è€…')
        text = msg.get('text', '').replace('\n', ' ')
        # è™•ç†å›è¦†è³‡è¨Šï¼ˆå›è¦† preview + senderï¼‰
        reply_to_list = msg.get('reply_to_id', [])
        if isinstance(reply_to_list, list) and len(reply_to_list) > 0:
            reply_info = reply_to_list[0]  # ç›®å‰åƒ…ä½¿ç”¨ç¬¬ä¸€å€‹å›è¦†å°è±¡
            reply_sender = reply_info.get("sender", "æœªçŸ¥å°è±¡")
            msg_preview = reply_info.get("msg_preview", "").strip().replace('\n', ' ')
            reply_tag = f"(å›è¦†: {reply_sender}ã€Œ{msg_preview}ã€)"
        else:
            reply_tag = ""

        dialog_lines.append(f"{time} - {sender} {reply_tag}: {text}")

    dialog_text = "\n".join(dialog_lines)

    prompt = (
        """
        è«‹ä½ è¬›ä¸­æ–‡ã€‚
        ä½ æ˜¯ä¸€ä½æœƒè­°å°è©±åˆ†æå¸«ï¼Œå°ˆé–€å¾åœ˜éšŠèŠå¤©å®¤ä¸­æ‰¾å‡ºé‚£äº›æå•ä½†å®Œå…¨æ²’æœ‰äººå›æ‡‰çš„å•é¡Œã€‚

        è«‹é€æ­¥æ€è€ƒæ¯ä¸€å‰‡è¨Šæ¯ï¼Œæµç¨‹å¦‚ä¸‹ï¼š
        1. åˆ¤æ–·é€™å‰‡è¨Šæ¯æ˜¯å¦ç‚ºä¸€å€‹å•é¡Œï¼ˆå³è©¢å•æŸäººæŸäº‹ï¼‰ã€‚
        2. å¦‚æœæ˜¯å•é¡Œï¼Œå†åˆ¤æ–·æ˜¯å¦æœ‰ä»»ä½•äººå°æ­¤è¨Šæ¯é€²è¡Œäº†å›æ‡‰ï¼ˆç„¡è«–å…§å®¹æ˜¯å¦å®Œæ•´ï¼Œåªè¦æœ‰ã€Œå›è¦†ã€å³è¦–ç‚ºå·²å›æ‡‰ï¼‰ã€‚

        âš ï¸ åƒ…ç•¶å•é¡Œ**å®Œå…¨æ²’æœ‰ä»»ä½•å›æ‡‰**æ™‚ï¼Œæ‰è¦–ç‚ºã€Œæœªå›æ‡‰å•é¡Œã€ã€‚
        - è‹¥æœ‰å…¶ä»–äººç¨ä½œå›æ‡‰ã€è¡¨é”çœ‹æ³•ã€æˆ–åƒ…éƒ¨åˆ†å›è¦†ï¼Œä¹Ÿç®—ã€Œæœ‰å›æ‡‰ã€ã€‚
        - å³ä½¿å›è¦†ä¸æ˜¯ç›´æ¥å›ç­”å•é¡Œï¼Œåªè¦æœ‰ã€Œå›æ‡‰ã€å‹•ä½œå°±ç®—ã€‚

        å¦‚æœæ‰€æœ‰å•é¡Œéƒ½æœ‰è¢«å›æ‡‰ï¼Œè«‹åªå›è¦† `None`ã€‚

        è‹¥æœ‰æ‰¾åˆ°æœªè¢«å›æ‡‰çš„å•é¡Œï¼Œè«‹ä»¥å¦‚ä¸‹æ ¼å¼åˆ—å‡ºï¼Œ**ä¸è¦åŒ…å«å¤šé¤˜å°è©±**ï¼š
        ---
        å•é¡Œå…§å®¹ï¼š
        æå•è€…ï¼š
        æ™‚é–“ï¼š
        ç‚ºä½•è¢«è¦–ç‚ºæœªå›æ‡‰å•é¡Œï¼š

        [ä»¥ä¸‹æ˜¯å°è©±å…§å®¹]
        """
        f"{dialog_text}\n"
    )
    prompt = prompt.replace('\n',' ').replace('\xa0',' ')
    return  prompt

def analyze_unanswered_questions(raw_chat, model):
    processed_msgs = parse_graph_chat_messages(raw_chat)
    prompt = make_prompt_for_unanswered_questions(processed_msgs)
    # ç¬¬ä¸€æ¬¡æ¨ç†
    first_response = model.generate_content(
        prompt,
        generation_config={
            "temperature": 0,
            "top_p": 0,
            "top_k": 1,
            "max_output_tokens": 1024,
            "stop_sequences": []
        }
    ).text

    print("ğŸ” åˆæ­¥å›æ‡‰ï¼š\n", first_response)

    # ç¬¬äºŒæ¬¡ refine
    refine_prompt = f"""ä½ å‰›æ‰çš„å›æ‡‰æ˜¯ï¼š
    {first_response}

    è«‹ä½ å¹«æˆ‘åšä»¥ä¸‹ç²¾ç…‰ï¼š
    - ç¢ºä¿ç†ç”±ä¸­è‹¥æ˜¯ä½¿ç”¨åå‘èªæ°£ï¼ˆæåŠé›–ç„¶ã€ä½†æ˜¯ï¼‰ï¼Œå‰‡åˆªé™¤æ•´å€‹å•é¡Œå…§å®¹
    - è‹¥ç†ç”±ç‚ºéå®Œæ•´å›æ‡‰ï¼Œå‰‡åˆªé™¤æ•´å€‹å•é¡Œå…§å®¹
    - å¦‚æœæ ¼å¼ç¬¦åˆè¦ç¯„ä¸”æ²’éŒ¯èª¤ï¼Œå°±åŸæ¨£è¼¸å‡º
    - å¦‚æœä½ åˆªå…‰äº†ï¼Œè«‹å›è¦† `None`ã€‚

    è«‹ç›´æ¥è¼¸å‡ºç²¾ç…‰å¾Œçš„ç‰ˆæœ¬ï¼Œä¸è¦è£œå……èªªæ˜ã€‚"""

    refined_response = model.generate_content(
        refine_prompt,
        generation_config={
            "temperature": 0,
            "top_p": 0,
            "top_k": 1
        }
    ).text

    print("âœ¨ ç²¾ç…‰å¾Œçµæœï¼š\n", refined_response)
    return refined_response