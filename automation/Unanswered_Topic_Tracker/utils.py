from typing import List, Dict, Any
from bs4 import BeautifulSoup
import json
from google import generativeai as genai
import yaml
import re

class UnansweredTopicTrackerUtils:
    def __init__(self, config_path="/app/core/oauth_settings.yml"):
        with open(config_path, "r") as f:
            config = yaml.safe_load(f)
        self.GEMINI_API_KEY = config['GEMINI_API_KEY']
        genai.configure(api_key=self.GEMINI_API_KEY)
        self.model = genai.GenerativeModel(model_name="gemini-1.5-flash")

    def parse_unanswered_questions(self, llm_output: str):
        if llm_output.strip().lower() == 'none':
            return []

        blocks = re.split(r'-{3,}', llm_output)
        results = []

        for block in blocks:
            block = block.strip()
            if not block:
                continue

            def extract(pattern):
                match = re.search(pattern, block)
                return match.group(1).strip() if match else ""

            reason_match = re.search(r'ç‚ºä½•è¢«è¦–ç‚ºæœªå›æ‡‰å•é¡Œï¼š(.+)', block, re.DOTALL)

            results.append({
                "question": extract(r'å•é¡Œå…§å®¹ï¼š(.+?)\n'),
                "asker": extract(r'æå•è€…ï¼š(.+?)\n'),
                "timestamp": extract(r'æ™‚é–“ï¼š(.+?)\n'),
                "reason": reason_match.group(1).strip() if reason_match else "",
            })

        return results



    def parse_graph_chat_messages(self, messages: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        parsed = []
        for msg in messages:
            msg_id = msg.get('id', '')
            if msg.get('from') is None:
                continue
            sender = msg.get('from', {}).get('user', {}).get('displayName', 'Unknown')
            html_content = msg.get('body', {}).get('content', '')
            timestamp = msg.get('createdDateTime', '')
            reply_to_id = []
            attachments = msg.get('attachments', [])
            for attachment in attachments:
                if attachment.get("contentType") == "messageReference":
                    try:
                        referenced_msg = json.loads(attachment.get("content", "{}"))
                        if reply_to_id is not None:
                            reply_to_id.append({
                                "msg_id": referenced_msg.get("messageId"),
                                "sender": referenced_msg.get("messageSender").get('user').get('displayName'),
                                "msg_preview": referenced_msg.get("messagePreview")
                            })
                    except Exception as e:
                        print(f"Error parsing messageReference: {e}")
            soup = BeautifulSoup(html_content, 'html.parser')
            clean_text = soup.get_text(separator='\n').strip()
            parsed.append({
                "id": msg_id,
                "sender": sender,
                "text": clean_text,
                "timestamp": timestamp,
                "reply_to_id": None if len(reply_to_id) == 0 else reply_to_id
            })
        return parsed

    def make_prompt_for_unanswered_questions(self, processed_msgs: List[Dict], max_len=None):
        sorted_msgs = sorted(processed_msgs, key=lambda x: x.get('timestamp', ''))
        dialog_lines = []
        for count, msg in enumerate(sorted_msgs):
            if max_len and count >= max_len:
                break
            time = msg.get('timestamp', 'æœªçŸ¥æ™‚é–“')
            sender = msg.get('sender', 'æœªçŸ¥ç™¼è©±è€…')
            text = msg.get('text', '').replace('\n', ' ')
            reply_to_list = msg.get('reply_to_id', [])
            if isinstance(reply_to_list, list) and len(reply_to_list) > 0:
                reply_info = reply_to_list[0]
                reply_sender = reply_info.get("sender", "æœªçŸ¥å°è±¡")
                msg_preview = reply_info.get("msg_preview", "").strip().replace('\n', ' ')
                reply_tag = f"(å›è¦†: {reply_sender}ã€Œ{msg_preview}ã€)"
            else:
                reply_tag = ""
            dialog_lines.append(f"{time} - {sender} {reply_tag}: {text}")
        dialog_text = "\n".join(dialog_lines)
        prompt = (
            """
            è«‹ä½ è¬›ä¸­æ–‡ã€‚
            ä½ æ˜¯ä¸€ä½æœƒè­°å°è©±åˆ†æå¸«ï¼Œå°ˆé–€å¾åœ˜éšŠèŠå¤©å®¤ä¸­æ‰¾å‡ºé‚£äº›æå•ä½†å®Œå…¨æ²’æœ‰äººå›æ‡‰çš„å•é¡Œã€‚

            è«‹é€æ­¥æ€è€ƒæ¯ä¸€å‰‡è¨Šæ¯ï¼Œæµç¨‹å¦‚ä¸‹ï¼š
            1. åˆ¤æ–·é€™å‰‡è¨Šæ¯æ˜¯å¦ç‚ºä¸€å€‹å•é¡Œï¼ˆå³è©¢å•æŸäººæŸäº‹ï¼‰ã€‚
            2. å¦‚æœæ˜¯å•é¡Œï¼Œå†åˆ¤æ–·æ˜¯å¦æœ‰ä»»ä½•äººå°æ­¤è¨Šæ¯é€²è¡Œäº†å›æ‡‰ï¼ˆç„¡è«–å…§å®¹æ˜¯å¦å®Œæ•´ï¼Œåªè¦æœ‰ã€Œå›è¦†ã€å³è¦–ç‚ºå·²å›æ‡‰ï¼‰ã€‚

            âš ï¸ åƒ…ç•¶å•é¡Œ**å®Œå…¨æ²’æœ‰ä»»ä½•å›æ‡‰**æ™‚ï¼Œæ‰è¦–ç‚ºã€Œæœªå›æ‡‰å•é¡Œã€ã€‚
            - è‹¥æœ‰å…¶ä»–äººç¨ä½œå›æ‡‰ã€è¡¨é”çœ‹æ³•ã€æˆ–åƒ…éƒ¨åˆ†å›è¦†ï¼Œä¹Ÿç®—ã€Œæœ‰å›æ‡‰ã€ã€‚
            - å³ä½¿å›è¦†ä¸æ˜¯ç›´æ¥å›ç­”å•é¡Œï¼Œåªè¦æœ‰ã€Œå›æ‡‰ã€å‹•ä½œå°±ç®—ã€‚

            å¦‚æœæ‰€æœ‰å•é¡Œéƒ½æœ‰è¢«å›æ‡‰ï¼Œè«‹åªå›è¦† `None`ã€‚

            è‹¥æœ‰æ‰¾åˆ°æœªè¢«å›æ‡‰çš„å•é¡Œï¼Œè«‹ä»¥å¦‚ä¸‹æ ¼å¼åˆ—å‡ºï¼Œ**ä¸è¦åŒ…å«å¤šé¤˜å°è©±**ï¼š
            ---
            å•é¡Œå…§å®¹ï¼š
            æå•è€…ï¼š
            æ™‚é–“ï¼š
            ç‚ºä½•è¢«è¦–ç‚ºæœªå›æ‡‰å•é¡Œï¼š

            [ä»¥ä¸‹æ˜¯å°è©±å…§å®¹]
            """
            f"{dialog_text}\n"
        )
        prompt = prompt.replace('\n', ' ').replace('\xa0', ' ')
        return prompt

    def analyze_unanswered_questions(self, raw_chat):
        processed_msgs = self.parse_graph_chat_messages(raw_chat)
        prompt = self.make_prompt_for_unanswered_questions(processed_msgs)
        first_response = self.model.generate_content(
            prompt,
            generation_config={
                "temperature": 0,
                "top_p": 0,
                "top_k": 1,
                "max_output_tokens": 1024,
                "stop_sequences": []
            } # type: ignore
        ).text
        print("ğŸ” åˆæ­¥å›æ‡‰ï¼š\n", first_response)
        # refine_prompt = f"""ä½ å‰›æ‰çš„å›æ‡‰æ˜¯ï¼š
        # {first_response}

        # è«‹ä½ å¹«æˆ‘åšä»¥ä¸‹ç²¾ç…‰ï¼š
        # - è‹¥ç†ç”±ç‚ºéå®Œæ•´å›æ‡‰ï¼Œå‰‡åˆªé™¤æ•´å€‹å•é¡Œå…§å®¹
        # - å¦‚æœæ ¼å¼ç¬¦åˆè¦ç¯„ä¸”æ²’éŒ¯èª¤ï¼Œå°±åŸæ¨£è¼¸å‡º
        # - å¦‚æœä½ åˆªå…‰äº†ï¼Œè«‹å›è¦† `None`ã€‚

        # è«‹ç›´æ¥è¼¸å‡ºç²¾ç…‰å¾Œçš„ç‰ˆæœ¬ï¼Œä¸è¦è£œå……èªªæ˜ã€‚"""
        # refined_response = self.model.generate_content(
        #     refine_prompt,
        #     generation_config={
        #         "temperature": 0,
        #         "top_p": 0,
        #         "top_k": 1
        #     } # type: ignore
        # ).text
        # print("âœ¨ ç²¾ç…‰å¾Œçµæœï¼š\n", refined_response)
        return self.parse_unanswered_questions(first_response)
